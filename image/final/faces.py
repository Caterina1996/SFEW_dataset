# -*- coding: utf-8 -*-
"""FACES.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qmzr354dDLn6MMeyNCea8t9-yjw1c_HB

<a href="https://colab.research.google.com/github/Caterina1996/SFEW_dataset/blob/master/FACES_SFEW.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

## **FACES DATASET NOTEBOOK**

Entrenamos el modelo base con el dataset FACES y guardamos el modelo
"""

from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

!rm -rf Train2
!rm -rf Test2

!unzip "/content/gdrive/My Drive/Train2.zip"
!unzip "/content/gdrive/My Drive/Test2.zip"

import operator

import keras
import numpy as np
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dropout, Flatten, Dense, Conv2D, BatchNormalization, MaxPooling2D
from keras import applications

from sklearn.metrics import confusion_matrix
import itertools
import matplotlib.pyplot as plt
from keras.models import load_model
from keras.callbacks import ModelCheckpoint
import tensorflow as tf

tf.compat.v1.set_random_seed(1234)
from numpy.random import seed
seed(21)

import tensorflow
tensorflow.random.set_seed(21)

#PARAMS

img_width, img_height =128, 128

LR = 0.00001
epochs = 100
batch_size = 1

num_classes=6
dropout = 0.25

train_dir='Train2'
test_dir='Test2'

! ls SFEW_dataset/Train

! ls Train2

"""Todas las emociones del FACES son comunes al SFEW

"""

# 1) Entrenamos usando la arquitectura base con el FACES

datagen = ImageDataGenerator(rescale=1. / 255)

train_set = datagen.flow_from_directory(
    train_dir,
    #classes=['Anger','Disgust','Fear','Happiness','Sadness'],
    target_size=(img_width, img_height),
    batch_size=1,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=True)

nb_train_samples = len(train_set.filenames)

test_set = datagen.flow_from_directory(
    test_dir,
    # classes=['Anger','Disgust','Fear','Happiness','Sadness'],
    target_size=(img_width, img_height),
    batch_size=1,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=True)

nb_test_samples = len(test_set.filenames)

"""**Modelo base:**"""

def CNNmodel():
    model = Sequential()
    
    model.add(Conv2D(filters=32, kernel_size=(3, 3), 
                     input_shape = ( img_height, img_width,1), 
                     activation = 'relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))#--
    model.add(BatchNormalization())
    model.add(Dropout(dropout))
    
    model.add(Conv2D(filters=64, kernel_size=(3, 3),activation = 'relu'))
    model.add(BatchNormalization())
    model.add(Dropout(dropout*2))
    model.add(MaxPooling2D(pool_size = (2, 2)))
    
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dense(6, activation='softmax'))
    return model

from keras.callbacks import ModelCheckpoint,CSVLogger
filepath="/content/gdrive/My Drive/FACES_SFEW/Test2/:{epoch:03d}-val_acc:{val_accuracy:.3f}.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

E_stopping=tf.keras.callbacks.EarlyStopping(monitor="val_accuracy",
                                              min_delta=0,
                                              patience=40,
                                              verbose=1,
                                              mode="auto",
                                              restore_best_weights=True)

csv_logger = CSVLogger('/content/gdrive/My Drive/TFM_MUSI/training.log')
callbacks_list = [checkpoint,E_stopping]

Classifier=CNNmodel()
opt=keras.optimizers.SGD(lr=LR)
Classifier.compile(optimizer=opt,
                  loss='categorical_crossentropy', metrics=['categorical_accuracy','accuracy'])

Classifier.summary()

def plot_model(history,title):
  plt.figure()
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  # plt.plot(history.history['val_categorical_accuracy'])
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'val'], loc='upper left')

  plt.title("model train and val accuracy "+title)
  # plt.show()
  
  plt.figure()
  plt.plot(history.history['val_accuracy'])
  plt.title("Validation accuracy " + title)

  plt.figure()
  plt.plot(history.history['val_categorical_accuracy'])
  plt.title("Validation categorical accuracy"+title)
  # print(history.history.keys())

""" **Entrenamiento del modelo base con el FACES**"""

history=Classifier.fit_generator(train_set,
                         steps_per_epoch = nb_train_samples//batch_size,
                         epochs = 75,
                         validation_data = test_set,
                         validation_steps = nb_test_samples//batch_size,
                         callbacks=callbacks_list)

#Guardamos el modelo obtenido:

"""**Gr√†fica del resultado**

Figura 6: Train y validation accuracy obtenida por el modelo entrenado con el FACES
"""

import os
dir="/content/gdrive/MyDrive/TF_VGG16/FACES_SFEW/Test2/"
Classifier.save(dir+"FACES_SFEW.h5")
if os.path.exists(dir)==False:
  os.makedirs(dir)
Classifier.save(dir+"FACES_SFEW.h5")
title="Arquitectura base con el dataset FACES"
plot_model(history,title)

Classifier.save('emotionsFACES.h5')

Classifier.save('modelo_base_FACES.h5') # guardamos el modelo







#Test del modelo:

#Cargamos el modelo obtenido y lo testeamos con los dos datasets:

#Testeamos el modelo con el FACES i con el SFEW:
datagen = ImageDataGenerator(rescale=1. / 255)
test_set = datagen.flow_from_directory(
    'Test2',
    target_size=(img_width, img_height),
    batch_size=1,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False)

a = Classifier.evaluate(test_set,steps=16)
print(a)
# print(test_loss," ",test_acc)

predictions=Classifier.predict(test_set)

print('Confusion Matrix')
ypred=[round(list(i).index(max(i))) for i in predictions]
print(confusion_matrix(test_set.classes, ypred)[:,:])
print(test_set.label_indices)

emofaces6=load_model('6emotionsFACES.h5')

import os
dir="/content/gdrive/MyDrive/TF_VGG16/FACES_SFEW/Test2/"
emofaces6=load_model(dir+"FACES_SFEW.h5")

#Testeamos el modelo con el FACES i con el SFEW:
datagen = ImageDataGenerator(rescale=1. / 255)
test_set = datagen.flow_from_directory(
    'Test2',
    target_size=(img_width, img_height),
    batch_size=1,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False)

a = emofaces6.evaluate(test_set,steps=16)
print(a)
# print(test_loss," ",test_acc)

predictions=emofaces6.predict(test_set)

print('Confusion Matrix')
ypred=[round(list(i).index(max(i))) for i in predictions]
print(confusion_matrix(test_set.classes, ypred)[:,:])

print(test_set.class_indices)
emotions_dict = {v: k for k, v in test_set.class_indices.items()}
print(emotions_dict)

datagen = ImageDataGenerator(rescale=1. / 255)

train_set = datagen.flow_from_directory(
    "SFEW_dataset/Train",
    classes=['Angry','Disgust','Fear','Happy','Neutral','Sad'],
    target_size=(img_width, img_height),
    batch_size=1,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=True)

nb_train_samples = len(train_set.filenames)

test_set = datagen.flow_from_directory(
    "SFEW_dataset/Val",
    classes=['Angry','Disgust','Fear','Happy','Neutral','Sad'],
    target_size=(img_width, img_height),
    batch_size=1,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=True)

nb_test_samples = len(test_set.filenames)

#Reentrenamiento del modelo
from keras.callbacks import ModelCheckpoint,CSVLogger
filepath="/content/gdrive/My Drive/FACES_SFEW/SFEW_training/:{epoch:03d}-val_acc:{val_accuracy:.3f}.hdf5"
if os.path.exists(filepath)==False:
  os.makedirs(filepath)

checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

E_stopping=tf.keras.callbacks.EarlyStopping(monitor="val_accuracy",
                                              min_delta=0,
                                              patience=40,
                                              verbose=1,
                                              mode="auto",
                                              restore_best_weights=True)

# csv_logger = CSVLogger('/content/gdrive/My Drive/TFM_MUSI/training.log')
callbacks_list = [checkpoint,E_stopping]

history=emofaces6.fit_generator(train_set,
                         steps_per_epoch = nb_train_samples//batch_size,#nb_train_samples//batch_size,
                         epochs = 75,
                         validation_data = test_set,
                         validation_steps = nb_test_samples//batch_size,#nb_test_samples//batch_size,
                         callbacks=callbacks_list)

emofaces6.save(dir+"SFEW_6_emo.h5")
title="Modelo entrenado con el FACES y reentrenado con el SFEW"
plot_model(history,title)

#Testeamos el modelo con el FACES i con el SFEW:
datagen = ImageDataGenerator(rescale=1. / 255)
test_set = datagen.flow_from_directory(
    'SFEW_dataset/Val',
    classes=['Angry','Disgust','Fear','Happy','Neutral','Sad'],
    target_size=(img_width, img_height),
    batch_size=1,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False)

a = emofaces6.evaluate(test_set,steps=16)
print(a)
# print(test_loss," ",test_acc)

predictions=emofaces6.predict(test_set)

print('Confusion Matrix')
ypred=[round(list(i).index(max(i))) for i in predictions]
print(confusion_matrix(test_set.classes, ypred)[:,:])

print(test_set.class_indices)
emotions_dict = {v: k for k, v in test_set.class_indices.items()}
print(emotions_dict)

#Dataug

import os
dir="/content/gdrive/MyDrive/TF_VGG16/FACES_SFEW/Test2/"
FACES_SFEW_model=load_model(dir+"FACES_SFEW.h5")

FACES_SFEW_model.summary()

datagen = ImageDataGenerator(rescale=1. / 255)

train_datagen = ImageDataGenerator(rescale=1. / 255,
                                   brightness_range=[0.5,1.0],
                                   zoom_range=0.1,
                                   shear_range=0.2,
                                  #  height_shift_range=0.1,
                                   horizontal_flip=True)
                                  #  height_shift_range=0.1

train_set = train_datagen.flow_from_directory(
    "SFEW_dataset/Train",
    classes=['Angry','Disgust','Fear','Happy','Neutral','Sad'],
    target_size=(img_width, img_height),
    batch_size=1,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=True)

nb_train_samples = len(train_set.filenames)

test_set = datagen.flow_from_directory(
    "SFEW_dataset/Val",
    classes=['Angry','Disgust','Fear','Happy','Neutral','Sad'],
    target_size=(img_width, img_height),
    batch_size=1,
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=True)

nb_test_samples = len(test_set.filenames)

from keras.callbacks import ModelCheckpoint,CSVLogger
filepath="/content/gdrive/My Drive/FACES_SFEW/Dataug/:{epoch:03d}-val_acc:{val_accuracy:.3f}.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

E_stopping=tf.keras.callbacks.EarlyStopping(monitor="val_accuracy",
                                              min_delta=0,
                                              patience=25,
                                              verbose=1,
                                              mode="auto",
                                              restore_best_weights=False)

callbacks_list = [checkpoint,E_stopping]

history=FACES_SFEW_model.fit_generator(train_set,
                         steps_per_epoch = nb_train_samples//batch_size,#nb_train_samples//batch_size,
                         epochs = 100,
                         validation_data = test_set,
                         validation_steps = nb_test_samples)
                        #  callbacks=callbacks_list)

dir="/content/gdrive/My Drive/FACES_SFEW/Dataug/"
FACES_SFEW_model.save(dir+"SFEW_6_emo_dataug.h5")
title="Modelo entrenado con el FACES y reentrenado con el SFEW con dataugmentation"
plot_model(history,title)



#Testeamos el modelo con el FACES i con el SFEW:
test_set = datagen.flow_from_directory(
    'SFEW_dataset/Val',
    target_size=(img_width, img_height),
    batch_size=1,
    classes=['Angry','Disgust','Fear','Happy','Sad','Neutral'],
    class_mode='categorical',
    color_mode='grayscale',
    shuffle=False)

predictions=FACES_SFEW_model.predict(test_set)

print('Confusion Matrix')
ypred=[round(list(i).index(max(i))) for i in predictions]
print(confusion_matrix(test_set.classes, ypred)[:,:])

FACES_SFEW_model.evaluate_generator(test_set)
test_set.class_indices













